{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 Nano model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"data\\State-wise_OLX\\AN\\AN1.jpg\"  # Replace with your image path\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform inference\n",
    "results = model(image)\n",
    "\n",
    "# Parse and visualize results\n",
    "annotated_frame = results[0].plot()\n",
    "\n",
    "# Display the image with detections\n",
    "cv2.imshow('YOLOv8n Detection', annotated_frame)\n",
    "cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Optionally, save the annotated image\n",
    "cv2.imwrite('annotated_image.jpg', annotated_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO models\n",
    "vehicle_model = YOLO('yolov8n.pt')  # Vehicle detection model\n",
    "plate_model = YOLO('license_plate_detector.pt')  # License plate detection model (change to your model path)\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"data\\State-wise_OLX\\AN\\AN1.jpg\"  # Replace with your image path\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform vehicle detection\n",
    "vehicle_results = vehicle_model(image)\n",
    "\n",
    "# Initialize lists for detected vehicles and their corresponding number plates\n",
    "vehicles = []\n",
    "\n",
    "# Loop through vehicle detection results\n",
    "for result in vehicle_results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        class_name = result.names[int(box.cls[0])]  # Get the class name\n",
    "        if class_name in ['car', 'bus', 'truck', 'motorcycle']:  # Filter for vehicle classes\n",
    "            vehicles.append(box.xyxy[0].cpu().numpy().astype(int))  # Store bounding box\n",
    "\n",
    "# Now run license plate detection on the cropped vehicle images\n",
    "for vehicle_box in vehicles:\n",
    "    x_min, y_min, x_max, y_max = vehicle_box\n",
    "    vehicle_crop = image[y_min:y_max, x_min:x_max]  # Crop the vehicle region\n",
    "\n",
    "    # Perform license plate detection on the cropped vehicle image\n",
    "    plate_results = plate_model(vehicle_crop)\n",
    "\n",
    "    # Loop through plate detection results\n",
    "    for plate_result in plate_results:\n",
    "        plates = plate_result.boxes\n",
    "        for plate in plates:\n",
    "            plate_box = plate.xyxy[0].cpu().numpy().astype(int)\n",
    "            # Annotate the license plate on the vehicle crop\n",
    "            cv2.rectangle(vehicle_crop, (plate_box[0], plate_box[1]), (plate_box[2], plate_box[3]), (255, 0, 0), 2)  # Blue for plates\n",
    "\n",
    "    # Display the annotated vehicle crop with plates\n",
    "    cv2.imshow(\"Detected Vehicle with Plates\", vehicle_crop)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Annotate and show the original image with vehicle detections\n",
    "for vehicle_box in vehicles:\n",
    "    cv2.rectangle(image, (vehicle_box[0], vehicle_box[1]), (vehicle_box[2], vehicle_box[3]), (0, 255, 0), 2)  # Green for vehicles\n",
    "\n",
    "# Display the image with detections\n",
    "cv2.imshow('YOLO Detection', image)\n",
    "cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Optionally, save the annotated image\n",
    "cv2.imwrite('annotated_image.jpg', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "\n",
    "# Ensure to specify the path to tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Change to your Tesseract path\n",
    "\n",
    "# Load the YOLOv8 Nano model for vehicle detection\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"data\\State-wise_OLX\\AN\\AN1.jpg\"  # Replace with your image path\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform inference to detect vehicles\n",
    "results = model(image)\n",
    "\n",
    "# Initialize list to store vehicle bounding boxes\n",
    "vehicles = []\n",
    "\n",
    "# Loop through the detected objects to filter for vehicles\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        # You can filter by class label, here we assume \"vehicle\" classes like car, truck, etc.\n",
    "        class_name = result.names[int(box.cls[0])]  # Get the class name\n",
    "        if class_name in ['car', 'bus', 'truck', 'motorcycle']:  # Filter vehicle classes\n",
    "            vehicles.append(box.xyxy[0].cpu().numpy().astype(int))  # Store vehicle bounding box\n",
    "\n",
    "# Now we process each detected vehicle\n",
    "for vehicle_box in vehicles:\n",
    "    x_min, y_min, x_max, y_max = vehicle_box\n",
    "    vehicle_crop = image[y_min:y_max, x_min:x_max]  # Crop the vehicle region from the image\n",
    "    \n",
    "    # Display the detected vehicle\n",
    "    cv2.imshow(\"Detected Vehicle\", vehicle_crop)\n",
    "    \n",
    "    # Perform OCR to detect the number plate in the vehicle region\n",
    "    # You can adjust the region where the number plate is likely to appear, based on your use case\n",
    "    ocr_result = pytesseract.image_to_string(vehicle_crop)\n",
    "    \n",
    "    if ocr_result.strip():\n",
    "        print(\"Detected Number Plate Text:\", ocr_result)\n",
    "    else:\n",
    "        print(\"No number plate detected in this vehicle.\")\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Annotate and show the original image with vehicle detections\n",
    "annotated_frame = results[0].plot()\n",
    "\n",
    "# Display the image with detections\n",
    "cv2.imshow('YOLOv8n Detection', annotated_frame)\n",
    "cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Optionally, save the annotated image\n",
    "cv2.imwrite('annotated_image.jpg', annotated_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "import PIL.Image\n",
    "\n",
    "# Load API key from .env file\n",
    "def load_api_key():\n",
    "    with open('.env') as f:\n",
    "        return dict(line.strip().split('=', 1) for line in f if '=' in line).get('gemini_api_key')\n",
    "    \n",
    "API_KEY = load_api_key()\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "image_path = \"data\\State-wise_OLX\\AN\\AN1.jpg\"\n",
    "\n",
    "# Prompt\n",
    "prompt = (\n",
    "    \"Identify if you could find a vehicle in the provided image. \"\n",
    "    \"Classify if the vehicle is 'Car', 'Bike', 'Auto rickshaw', or 'Heavy Vehicle' and provide number plate details. \"\n",
    "    \"Provide output in 'vehicle_type', 'vehicle_number', 'vehicle_approch[in-if the vechicle front side or out-if vechicle back side]'.\"\n",
    ")\n",
    "\n",
    "# Prepare input\n",
    "myfile = genai.upload_file(path=image_path)\n",
    "inputs = [prompt,myfile]\n",
    "\n",
    "# Generate content\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(inputs)\n",
    "myfile.delete()\n",
    "\n",
    "# Display the response\n",
    "\n",
    "response.resolve()\n",
    "# Markdown(\"> \" + response.text)\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envVechicleInOutAITracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
